---
title: "Linear Regression"
author: "Dorothee Mersch"
date: "8 Juli 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<div style="text-align: justify">
# Linear Regresssion Analysis

## Table of content
1. [1. Univariate Regression: IC50 - RGES <a name="cleanup"></a> ](#1.lm)  
    1.1. [Introdcution](#intro)
    1.2. [Variable RGES](#rges)
        1.2.1. [Correlation IC50 - RGES](#cor)
        1.2.2. [Computation univariate model](#comp)
        1.2.3. [Result univariate model: IC50 - RGES:](#res)
        1.2.4. [Prediction of IC50 data](#pred)
2. [Multiple Regression Model Cisplatin](#2.lm)  
    2.1. [Variables: RGES and biomarkers](#bio)  
        2.1.2. [Correlation between IC50, RGES and Biomarkers](#cor2)
        2.1.3. [Computation of multiple regression model](#comp2)
        2.1.4. [Prediction of IC50 values cisplatin](#pred2)
    2.2. [Multiple Regression Model selected biomarkers](#3.lm)
        2.2.1. [Variables: 4 biomarkers (PTPRG, FARS2, GMDS, PLCB1)](#var3)
        2.2.2. [Computation of the model with specific biomarkers](#comp3)
        2.2.3. [Prediction of IC50 values](#pred3)
    2.3. [Multiple Regression Model PCAs](#4.lm)
        2.3.1. [Variables: PCs](#var4)
        2.3.2. [Analysation of PC1](#ana)
        2.3.3. [Computation of the Model](#comp4)
        2.3.4. [Further ideas for an enhancement of the PC model](#idea)


## Used Library:
```{r, echo=TRUE}
library(reshape)
library(ggplot2)
```
```{r, echo=FALSE}
results = readRDS("C:/Users/Dori/Desktop/Studium/SS_19/Bioinfo Projekt/GitHub/project-02-group-02#project-02-group-02/data/results.rds")
ic50 = readRDS("C:/Users/Dori/Desktop/Studium/SS_19/Bioinfo Projekt/GitHub/project-02-group-02#project-02-group-02/data/NegLogGI50.rds")
meta = read.delim("C:/Users/Dori/Desktop/Studium/SS_19/Bioinfo Projekt/GitHub/project-02-group-02#project-02-group-02/data/NCI_TPW_metadata.tsv")
```

## Data adjustment

In oder to create a vector, which contains all IC50 values per cell line, the melt function was used.
Afterwards NAs in the vector were removed. Then cell lines, that were included in the vector but not in the RGES result data, were deleted. Finally a new matrix containing RGES results and IC50 values was created and saved as drug_activity_rges. 

```{r, echo=TRUE, results="hide"}
# Create vector IC50 values
ic50 = t(ic50)
melt.data <- melt(ic50)
melt.data = as.matrix(melt.data)
melt.ic50 = as.data.frame(melt.data)
colnames(melt.ic50) = c("cell", "drug", "IC50")

# Remove NAs
rmv.rows = apply(melt.data, 1, function(x) {
  sum(is.na(x))
})
which(rmv.rows > 0)
melt.ic50 = melt.data[-which(rmv.rows > 0),]
rm(melt.data)

# Adjust cell lines of IC50 vector
IC50.value = c(rep(as.numeric(0),819))
results = cbind(results, IC50.value)

i=1
j=1

while(i<895)
{while(j<820)
{
  if(isTRUE(melt.ic50[i,1]== results[j,4])
     & (melt.ic50[i,2] == results[j,5]))
  {results[j,9] = as.numeric(melt.ic50[i,3])
  }
  j = j +1
}
  j= 1
  i=i+1}

which(results$IC50.value == 0)

# Define new matrix
drug_activity_rges = results[-which(results$IC50.value == 0),]
```

## 1. Univariate Regression: IC50 - RGES <a name="1.lm"></a> 
### 1.1. Introdcution <a name="intro"></a> 
Bin Chen *et al.* found out that RGES values positively correlate with IC50 values. This would mean, that the previously computed RGES values correlate with the IC50 data, which was checked. 
Afterwards a linear regression model was created in order to predict the antagonistic drug potency of the samples with RGES values. RGES is a value, which measures the drugs potency to reverse a disease induced gene expression.

### 1.2. Variable RGES <a name="rges"></a> 
First the data set was limited to numerical values. This resulted in a data frame with RGES and IC50 values.
```{r, echo=FALSE}
# limit the data set to numerical values
rges.ic50 <- as.data.frame(drug_activity_rges[,c(2,9)])
```

### 1.2.1 Correlation IC50 - RGES <a name="cor"></a> 

Furthermore the correlation between the computed RGES values and the IC50 values was checked. The spearman method was used as it is more robust.

Rho IC50 - RGES:
```{r, echo = TRUE, warning=F}
cor(rges.ic50$RGES, rges.ic50$IC50.value, method = "spearman")
```

Result of significance check:
```{r, echo=FALSE, include=TRUE}
cor.test(rges.ic50$RGES, rges.ic50$IC50.value, method = "spearman")
```

RGES values can also be plotted against IC50 values in order to visualize the correlation.
```{r,echo=FALSE, include=TRUE}
ggplot(rges.ic50, aes(rges.ic50$RGES, rges.ic50$IC50.value)) +
  geom_point(color = "blue", size = 1) +
  scale_size(range = c(2,5)) +
  xlab("RGES") + 
  ylab("IC50") 
```

The correlation coefficient as well as the plot of RGES values against the IC50 values are not convincing. The doubtful RGES values are very likely to be the reason as explained previously. Nevertheless a linear regression model was computed in order to predict the IC50 values with the previously computed RGES values. 

### 1.2.2 Computation univariate model <a name="comp"></a> 
A linear regression model should be learned on a training set. The training set is formed by 730 random variables of the data set (correspond to ~90 % of the whole data set). The remaining part of the data set is called test set. 
It was checked, whether the residuals are normal distributed and whether they correlate with x-values.

```{r, echo = TRUE}
i.train = sample(1:nrow(rges.ic50), 730)

rges.ic50.train = rges.ic50[i.train, ]
rges.ic50.test = rges.ic50[-i.train, ]
```


### 1.2.3 Result univariate model: IC50 - RGES: <a name="res"></a> 

```{r, echo = TRUE, include=TRUE}
lm.rges_ic50 = lm(IC50.value ~ RGES, data = rges.ic50.train)
```
```{r, echo=FALSE, include=TRUE}
summary(lm.rges_ic50)
```

Interpreting the output, the R squared value shows, that less than one percent of of total variance was explained by this model. In contrast, the F-statistic suggests, that the model was better than taking the mean of the drug sensitivity values. Also the p-value shows, that the intercept could not be 0. 
In summary, the model was not convincing at all as only a small amount of the variance was explained.

To analyze the residuals, they were plotted against the fitted values. A normal Quantile-Quantile plot was performed, in order to check the normal distribution of the residuals.

```{r, echo=TRUE, include=TRUE}
plot(lm.rges_ic50, which = c(1), pch=20, col="blue", main = "Scatter plot Residuals - Fitted values")
plot(lm.rges_ic50, which = c(2), pch=20, col="blue", main = "QQ plot Residuals")
```

Through the first plot, it was checked, whether the residuals have non-linear patterns. As the dots look more or less equally spread around the red line, there are no non-linear relationships.
Furthernmore, the QQ plot indicates a normal distribution of residuals.

To check if the residuals do correlate with x, the correlation between RGES and residuals was computed.
Correlation coefficient Residuals - RGES:
```{r, echo=TRUE, include=TRUE}
cor(rges.ic50.train$RGES, lm.rges_ic50$residuals)
```
The low value can be interpreted as no correlation between RGES and residuals.


### 1.2.4. Prediction of IC50 data <a name="pred"></a> 

Finally the training set was used to predict the antagonistic drug potency with RGES values.
```{r, echo = TRUE, include=TRUE}
pred = predict(lm.rges_ic50, newdata = rges.ic50.test)
plot(rges.ic50.test$IC50.value, pred, xlab = "Real Values", ylab = "Predicted Values", pch=20, col="blue", main = "Real Values - Predicted Values IC50")
abline(0, 1, col = "red")
```

Clearly the predicted values do not match the the real values since the blue dots should lay on the red line. Because of this the linear regression model was not ideal. 

##### Validity of the model 
In order to indicate how well the model matches the real data, the root mean square error (RMSE) was computed. 
```{r, echo = TRUE}
n = nrow(rges.ic50.train)
rmse.train = sqrt(1/n * sum(lm.rges_ic50$residuals^2))
n = nrow(rges.ic50.test)
residuals = rges.ic50.test$IC50.value - pred
rmse.test = sqrt(1/n * sum(residuals^2))
```
For the training set the following RMSE was obtained:
```{r, echo = FALSE, include=TRUE}
rmse.train
```
And for the test set the following RMSE was obtained:
```{r,echo=FALSE, include=TRUE}
rmse.test
```

A low RMSE indicates a good linear regression model. It should be close to zero. The obtained RMSE proved that the model did not match very well to the real data.  
In conclusion the RGES values did not have the capability to predict the IC50 values. Only a very small proportion of the variablity was explained by the model and the prediction results differ extremely from the real values.  
Due to these aspects, the univariate linear regression was expanded in order to enhance the model.



## 2. Multiple Regression Model Cisplatin <a name="2.lm"></a> 
### 2.1. Variabels: RGES and biomarkers <a name="bio"></a> 

In order to obtain an enhanced model, a multiple regression for IC50 values of  cisplatin was performed. The previously computed biomarkers for cisplatin were included. Then IC50 values were predicted with RGES values, as well as with genes, that showed the most extreme and constant fold change values between treated and untreated patients.
```{r, echo=FALSE}
#Multiple Regression
# Include biomarkers to RGES matrix only for cisplatin!
double.biomarker.FC <- readRDS("C:/Users/Dori/Desktop/Studium/SS_19/Bioinfo Projekt/GitHub/project-02-group-02#project-02-group-02/data/double.biomarker.FC.rds")
drug_activity_rges.cisplatin = subset (drug_activity_rges , drug == "cisplatin")
# transformieren, damit samples in zeile
biomarker.FC = t(double.biomarker.FC)

# fit both matrices
biomarker.FC.fit = subset(biomarker.FC, rownames(biomarker.FC) %in% drug_activity_rges.cisplatin$sample)

# limit the data set to numerical values: rges, ic50 and biomarkers:
rges.ic50.biomarkers <- as.data.frame(cbind(drug_activity_rges.cisplatin[,c(2,9)], biomarker.FC.fit))
```

### 2.1.2 Correlation between IC50, RGES and Biomarkers <a name="cor2"></a> 

To visualize the correlation pattern between Ic50 values, RGES and biomarkers, pairwise scatterplots, as well as a heatmap was produced. 
```{r, echo =TRUE, include= TRUE, dpi=250} 
pairs(rges.ic50.biomarkers, col = "blue", pch = 20, main = "Scatterplots RGES, IC50, Biomarkers")
```
```{r, echo=TRUE, include=TRUE, fig.align="center"}
cor.mat = cor(rges.ic50.biomarkers, method = "spearman")
heatmap(cor.mat, col = cm.colors(256), main = "Heatmap Correlation RGES, IC50, Biomarkers", symm = T)
```

In summary the correlation between biomarkers and IC50 values was quite low. One problematic aspect was the correlation between the variables. For example CUX1 and FARS2 showed a strong correlation. 
Nevertheless, a model with all variables was performed. 

### 2.1.3. Computation of multiple regression model <a name="comp2"></a> 

As before, in order to  perform a multiple regression model, the data set had to be splitted into two groups: a training set, which contained 45 random samples (~85% of the whole data set), and a test set out of the remaining values. 
```{r, echo = TRUE}
train.multiple = sample(1:nrow(rges.ic50.biomarkers), 45)
 
train.set.multiple = rges.ic50.biomarkers[train.multiple, ]
test.set.multiple = rges.ic50.biomarkers[-train.multiple, ]
```
  
Afterwards, the multiple regression model was learned from the test set. All variables were included. 
  
```{r, echo=TRUE, include=TRUE}
model.multiple = lm(IC50.value ~ ., data = train.set.multiple)
```
```{r, echo=FALSE, include=TRUE}
summary(model.multiple)
```
  
The R square value indicated, that ~15 % of the variability was explained by the model. Compared to the univariate regression model, the explained variability had improved greatly. 
Nevertheless the F-statistic was next to 1. 
In addition, the obtained p-values were quite high for some variables because of the correlation between some of them. 
   
In order to check the residuals, a scatterplot of residuals versus fitted values, as well as a normal QQ plot of the residuals was produced.

```{r, echo=FALSE, include=TRUE}
plot(model.multiple, which = c(1), col="blue", pch = 20, main = "Scatterplot Residuals - Fitted values")
plot(model.multiple, which = c(2), col="blue", pch = 20, main = "QQ plot Residuals")
```
  
As expected, the residuals were distributed around the red line and therefore did not have non-linear patterns. The QQ plot illustrated, that the residuals were normally distributed.

In order to prove the correlation between residuals and variables, the correlation coefficient was computed.
Correlation coefficient Residuals - Variables (RGES and biomarkers):
```{r, echo=FALSE, include=TRUE}
cor(train.set.multiple[,-2], model.multiple$residuals)
```
The low value indicated that the residuals did not correlate with x.



### 2.1.4. Prediction of IC50 values cisplatin <a name="pred2"></a> 

At the end the multiple regression model was used to predict the values.
```{r, echo = TRUE}
predict.multiple = predict(model.multiple, newdata = test.set.multiple)
```

```{r, echo=FALSE, include=TRUE}
plot(test.set.multiple$IC50.value, predict.multiple, xlab = "Real Values", ylab = "Predicted Values", pch=20, col="blue")
abline(0, 1, col = "red")
```

Because the test set contained only 9 value, which made it difficult to interpret the prediction. 
But in general the predicted values matched the real values better.
  
In conclusion, the multiple regression model with RGES and biomarkers enhanced the model as well as the prediction. 
  
  
#### Validity of the model

RMSE values for training and test set were computed.
```{r, echo=TRUE}
n = nrow(train.set.multiple)
rmse.train = sqrt(1/n * sum(model.multiple$residuals^2))
n = nrow(test.set.multiple)
residuals = test.set.multiple$IC50.value - predict.multiple
rmse.test = sqrt(1/n * sum(residuals^2))
```
RMSE training set:
```{r, echo = FALSE, include=TRUE}
rmse.train
```
RMSE test set:
```{r, echo=FALSE, include=TRUE}
rmse.test
```
The RMSE values for training and test set were closer to zero than previously. This indicated a better fit of the model to the real data than the univariate model.
  
  
In summary, inclusion of further variables, could improve the model. The explained variablilty, as well as the predicted values were enhanced.
  
  
Nevertheless the output showed high p values for some variables, which could be explained by a correlation between them.  
For that reason, the correlation between variables and drug sensitivity as well as the correlation between each explanatory variable was observed. Through a new model with variables, which show a more or less high correlation to IC50 as well as a low correlation to other explanatory variables the multiple regressioin model should be improved once again.



## 2.2. Multiple Regression Model selected biomarkers <a name="3.lm"></a> 
### 2.2.1. Variables: 4 biomarkers (PTPRG, FARS2, GMDS, PLCB1) <a name="var3"></a> 

The correlation heatmap including all variables, as well as the p-values suggest to perform a multiple regression model with four specific biomarkers. PTPRG, COMMD10, GMDS, LRBA showed low correlation between each other. Nevertheless the same training and test set as before is used.

### 2.2.2. Computation of the model with specific biomarkers <a name="comp3"></a> 
```{r, echo=TRUE, include=TRUE}
model.multiple.biomarkers = lm(IC50.value ~ PTPRG + COMMD10 + GMDS + LRBA, data = train.set.multiple)
``` 
```{r, echo=FALSE, include=TRUE}
summary(model.multiple.biomarkers)
```

The output illustrated that ~25 % of the variability was explained by the model. This was much more compared to the previous multiple regression model. Also the F-statistic showed a further enhancement and suggests, that the computed model was a better predictor for IC50 values than the mean would be. In general the p values were lower than before, but still higher than 0.1for some variables. This could be explained by a remaining correlation between these biomarkers.

The residuals were checked again:

```{r, echo=FALSE, include=TRUE}
plot(model.multiple.biomarkers, which = c(1), col = "blue", pch = 20, main = "Scatterplot Residuals - Fitted values")
plot(model.multiple.biomarkers, which = c(2), col = "blue", pch = 20, main = "QQ plot Residuals")
```

The residuals did not show non-linear relationships, and were normally distributed.

### 2.2.3. Prediction of IC50 values <a name="pred3"></a> 
Now the model was used to predict the data. 

```{r, echo = TRUE, include=TRUE}
predict.biomarkers = predict(model.multiple.biomarkers, newdata = test.set.multiple)
```
```{r, echo=FALSE, include=TRUE}
plot(test.set.multiple$IC50.value, predict.biomarkers, xlab = "Real Values", ylab = "Predicted Values", pch=20, col="blue")
abline(0, 1, col = "red")
```
  
The predicted values matched the real values better than previously. Although the test set size is small, one could observe some dots laying very close to the red line.
  
  
#### Validity of the model
To check the models validity, RMSE values for training and test set were computed.
```{r, echo=TRUE}
n = nrow(train.set.multiple)
rmse.train = sqrt(1/n * sum(model.multiple.biomarkers$residuals^2))
n = nrow(test.set.multiple)
residuals = test.set.multiple$IC50.value - predict.biomarkers
rmse.test = sqrt(1/n * sum(residuals^2))
```
RMSE training set:
```{r, echo = FALSE, include = TRUE}
rmse.train
```
RMSE test set:
```{r, echo = FALSE, include = TRUE}
rmse.test
```

Similar as before, the RMSE values were to zero, so that the model fit well to real data. 
All in all the multiple regression model with these 4 specific biomarkers improved the model very much. 
  
  
  
## 2.3. Multiple Regression Model PCAs <a name="4.lm"></a> 
### 2.3.1. Variables: PCs <a name="var4"></a> 

For a further enhancement of the multiple regression model, principle components were used instead of original variables. 
A barplot of the first principle component was computed. 

```{r, echo=TRUE}
pca = prcomp(rges.ic50.biomarkers[, -2])
```

### 2.3.2. Analysation of PC1 <a name="ana"></a> 
```{r, echo= FALSE, include=TRUE}
barplot(pca$rotation[, 1], horiz = TRUE, main = "Barplot PC1", col = "lightblue",las=1, cex.names = 0.5)
```

The RGES values did not contribute much to the variance explained by PC 1.
The highest variance is explained through the biomarkers DPYP, AGAP1 and CUX1.
First, a multiple regression model including all PCs was performed.

### 2.3.3. Computation of the Model <a name="comp4"></a> 
 
```{r, echo=TRUE}
model.pca = lm(rges.ic50.biomarkers$IC50.value ~ pca$x)
```
```{r, echo=FALSE, include=TRUE}
summary(model.pca)
```

A R square value of ~0.16 is obtained. So through the model less variability was explained than through the model with specific biomarkers. As the F-statistic was close to one, which shows that the computed model predicts the IC50 values better than the mean would do. In addition some variables showed a high p value. Therefore the correlation between the PCs was checked.

The residuals were checked:

```{r, echo=FALSE, include=TRUE}
plot(model.pca, which = c(1), col = "blue", pch = 20, main = "Scatterplot Residuals - Fitted values")
plot(model.pca, which = c(2), col = "blue", pch = 20, main = "QQ plot Residuals")
```

The two plots suggested, that the residuals were normally distributed. They also match the real data.

### 2.3.4. Further ideas for an enhancement of the PC model <a name="idea"></a> 

As high p values were obtained for some PCs, the correlation between them was checked.
  
```{r, echo=FALSE, include=TRUE}
cor.pca = cor(pca$x)
heatmap(cor.pca, col = cm.colors(256), main = "Heatmap Correlation PCs")
```
This showed that the high p values were not the result of a correlation between explanatory vaiables. 
  
  

The model could be improved by a new choice of PCs.
In order to look for the PCs which explain most of the data sets variance, an elbow plot was done.
```{r, echo=FALSE, include=TRUE}
plot(pca, type ="lines", main = "Elbow plot of PCA")
```

PC1 did contain most of the variance and PC2 a bit more than the following ones. This plot suggests to redo the multiple regression model with these two PCs.

</div>